---
permalink: /
title: "Mechanistic Interpretability in Large Language Models"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## ğŸ” Research Focus: Understanding the Inner Workings of LLMs

I am a Research Assistant at the University of TÃ¼bingen, working with [Dr. Thomas Wolfers](https://thomaswolfers.com/) and [Dr. Ã‡aÄŸatay YÄ±ldÄ±z](https://cagatayyildiz.github.io/) on the mechanistic interpretability of large language models. My research centers on developing novel approaches to understand how these complex systems acquire, represent, and access knowledge.

## ğŸ“° Recent News

<div class="news-box">
<ul>
<li><strong>June 2025:</strong> New preprint released: "<a href="https://arxiv.org/abs/2506.07658">Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping</a>" on arXiv</li>
<li><strong>April 2025:</strong> Paper "<a href="https://openreview.net/forum?id=aKjJoEVKgO">Investigating Continual Pretraining in Large Language Models</a>" accepted at TMLR</li>
<li><strong>April 2025:</strong> Started Research Assistant position at University of TÃ¼bingen under <a href="https://thomaswolfers.com/">Dr. Thomas Wolfers</a> and <a href="https://cagatayyildiz.github.io/">Dr. Ã‡aÄŸatay YÄ±ldÄ±z</a></li>
<li><strong>March 2025:</strong> Successfully defended Master's thesis on "Mechanistic Understanding of Factual Knowledge in LLMs" at <a href="https://bethgelab.org/">Bethge Lab</a></li>
<li><strong>2024:</strong> Awarded Deutschlandstipendium scholarship for outstanding academic achievements</li>
</ul>
</div>

## ğŸ§ª Current Research

My work focuses on two complementary areas:

**Knowledge Measurement & Evaluation**: Developing contamination-free evaluation frameworks for domain-specific knowledge in LLMs, extending beyond traditional perplexity metrics to understand true domain understanding.

**Activation Engineering**: Investigating how domain knowledge emerges as targetable directions in model activation space, enabling systematic control without traditional fine-tuning approaches.

## ğŸ’¡ Research Philosophy

Following Richard Feynman's principle "What I cannot create, I do not understand," my research aims to reverse-engineer the internal mechanisms of language models. By understanding how these systems process and represent knowledge, we can build more reliable, controllable, and interpretable AI systems.

## ğŸ”¬ Key Contributions

- **Domain-Specific Evaluation**: Created deterministic pipelines for contamination-free LLM evaluation using large-scale datasets (arXiv: 1.56M documents, M2D2: 8.5B tokens)
- **Continual Learning**: Investigated how model size affects knowledge acquisition and retention during continual pretraining across diverse domains
- **Activation Engineering**: Developed techniques to access latent knowledge through steering vectors and activation patterns

## ğŸ¯ Impact & Applications

This research enables practical breakthroughs in:
- **Model Efficiency**: Targeted knowledge editing without full retraining
- **Safety & Control**: Direct model steering through activation engineering  
- **Robust Evaluation**: Better understanding of what models truly know vs. memorize
- **Knowledge Transfer**: Optimizing how models adapt to new domains

---

*Research conducted at the [Bethge Lab](https://bethgelab.org/), [Vernade Lab](https://www.cvernade.com/), and in collaboration with the [Mental Health Mapping Lab](https://mhm-lab.github.io/), University of TÃ¼bingen.*
