---
layout: archive
title: "About Me"
permalink: /about_me/
author_profile: true
---

üîç **Research Journey**

My journey into understanding complex systems began at Indian Institute of Technology Roorkee, where I completed my Bachelor's in Engineering Physics, graduating with the Department Gold Medal (9.57/10) and Best Thesis Award in 2023. What started as curiosity about signal processing in Dr. R.S. Anand's lab, working on EEG-based epilepsy detection, evolved into a deeper fascination with neural systems and their computational understanding.

This pursuit led me to a DAAD WISE scholarship at Friedrich Schiller University, Jena, where I worked on MRI-based biomarkers for Major Depressive Disorder. The experience sparked my interest in bridging neuroscience with machine learning, ultimately leading to publications in Biological Psychiatry and successful pre-prints on ketamine's effects on brain connectivity.

Currently, I'm pursuing my Master's in Neural Information Processing at the University of T√ºbingen (1.24/4.0), supported by the Deutschlandstipendium scholarship. As a research assistant at the [Mental Health Mapping Lab](https://mhm-lab.github.io/) under [Dr. Thomas Wolfers](https://thomaswolfers.github.io/), I've been exploring the intersection of healthcare and AI, developing interpretable models for clinical applications. I'm particularly proud of our work on postoperative delirium prediction, where we emphasized model interpretability through SHAP values to ensure clinical relevance.

To complement my research in healthcare applications, I had the opportunity to explore two fascinating domains through my rotations. As part of my thesis, I conducted an essay rotation on "Large Language Models and Psychotherapy: Bridging the Gap with Mechanistic Interpretability" under Dr. Thomas Wolfers, which earned me the Best Presentation Award from the Graduate Training Centre of Neuroscience. Additionally, I pursued a lab rotation at the [Dayan lab](https://www.kyb.tuebingen.mpg.de/computational-neuroscience) (MPI for Biological Cybernetics) under [Dr. Sara Ershadmanesh](https://www.kyb.tuebingen.mpg.de/person/106573/2549), investigating metacognitive abilities in reversal learning tasks. These experiences deepened my understanding of how both biological and artificial systems learn and adapt to changing environments, while also highlighting the crucial role of interpretability in complex systems. This journey through different aspects of learning systems naturally led me to my current focus on mechanistic interpretability of AI systems.


üß™ **Current Focus**

Building on these experiences, I'm currently working on my master's thesis at the [Bethge Lab](https://bethgelab.org/), under [Prof. Matthias Bethge](https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/physik/institute/institut-fuer-theoretische-physik/arbeitsgruppen/ag-bethge/) and [Dr. √áaƒüatay Yƒ±ldiz](https://cagatayyildiz.github.io/). Here, I'm investigating how language models acquire and represent knowledge during continual pre-training across different domains, working with the vast arXiv dataset (over 1.5 million documents) to develop frameworks that can predict optimal pre-training domains for specific tasks based on patterns in the model's internal representations.

Parallel to my thesis work, I'm developing a GAMLSS-based Python package for neuroimaging applications at the Mental Health Mapping Lab under Dr. Thomas Wolfers. This package, which implements Generalized Additive Models for Location, Scale, and Shape, is already being utilized by lab members for their research and will be publicly released in early months of 2025.

From January to March 2025, I'll be continuing my exploration of AI interpretability as a HiWi under Dr. √áaƒüatay Yƒ±ldiz in [Claire Vernade's lab](https://www.cvernade.com/). I'm excited about contributing to the future of interpretable AI systems that can reliably serve human needs, and I'm currently working on manuscripts from both my thesis work and the normative modeling project.

üë®‚Äçüè´ **Teaching & Mentoring**

I believe in giving back to the academic community. As a Teaching Assistant for the Neuromatch Academy's Deep Learning Course (2024), I've had the privilege of guiding international students through complex concepts. My experience includes mentoring first-year students at IIT Roorkee and leading programming tutorials in the Academic Reinforcement Program.

üå± **Beyond Research**

When I'm not delving into neural networks, you'll find me on the beach volleyball court or training for long-distance runs - I've participated in 100km marathons at university! I'm also passionate about community service, having led initiatives like 'Daan Petika' during my time as an Executive at NSS IIT Roorkee, organizing blood donation camps and environmental cleanup drives. I believe in maintaining a balanced life that combines intellectual pursuits with physical activity and giving back to the community.

ü§ù **Let's Connect**

I'm actively seeking PhD positions and research internships in Machine Learning and AI, with a particular focus on LLM interpretability and mechanistic understanding. I'm also open to collaborations that align with my research interests - whether that's in AI, neuroscience, or at their intersection.

If my work intrigues you, I'd be happy to give a presentation or engage in an in-depth discussion about potential research synergies. And of course, I'm always up for a chat about research, AI, or volleyball! Feel free to reach out to me at [nitinsharma3150@gmail.com](nitinsharma3150@gmail.com).

Let's explore how we might work together to advance the field of interpretable AI!
